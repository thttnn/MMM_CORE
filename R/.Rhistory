#
# ====== STATISTICS GENERATION ======
#
# Create vectors and lists to hold the Monte Carlo results
gdp_gr <- gdp_gn <- inf <- u <- vector( mode = "numeric", length = nSize )
gdp_sd <- cr_sd <- ir_sd <- p_sd <- prod_sd <-  vector( mode = 'numeric', length = nSize )
gdp_gdp <- cr_gdp <- ir_gdp <- p_gdp <- prod_gdp <- inf_gdp <- u_gdp <- list( )
gdp_gdp_pval <- cr_gdp_pval <- ir_gdp_pval <- p_gdp_pval <-
prod_gdp_pval <- inf_gdp_pval <- u_gdp_pval <- vector( mode = "numeric", length = nExp )
adf_gdp_r <- adf_gdp_n <- adf_gdp_gr <- adf_gdp_gn <-
adf_cr <- adf_ir <- adf_p <- adf_prod <- list( )
for(k in 1 : nExp){ # Experiment k
#
# ---- Bandpass filtered GDP, consumption and investment cycles graphic ----
#
plot_bpf( list( log0( Adata[[ k ]]$Real_Q_GDP ), log0( Adata[[ k ]]$Q_C_r ),
log0( Adata[[ k ]]$Q_I_r ) ),
pl = lowP, pu = highP, nfix = bpfK, mask = TmaskPlot,
mrk = transMk, col = colors, lty = lTypes,
leg = c( "GDP", "Consumption", "Investment" ),
xlab = "Time", ylab = "Filtered series",
tit = paste( "GDP cycles (", legends[ k ], ")" ),
subtit = paste( "( Baxter-King bandpass-filtered, low = 6Q / high = 32Q / order = 12 / MC runs =",
nSize, ")" ) )
#
# ==== Statistics computation for tables ====
#
for( j in 1 : nSize ){  # Execute for every Monte Carlo run
# Monte carlo average growth rates
gdp_gr[ j ]       <- mcData[[ k ]][ nTstat, "G_r", j ]
gdp_gn[ j ]       <- mcData[[ k ]][ nTstat, "G_n", j ]
u[ j ]            <- mcData[[ k ]][ nTstat, "U", j ]
# Apply Baxter-King filter to the series
gdp_bpf     <- bkfilter( log0( mcData[[ k ]][ TmaskStat, "Real_Q_GDP", j ] ), pl = lowP, pu = highP, nfix = bpfK )
cr_bpf      <- bkfilter( log0( mcData[[ k ]][ TmaskStat, "Q_C_r", j ] ), pl = lowP, pu = highP, nfix = bpfK )
ir_bpf      <- bkfilter( log0( mcData[[ k ]][ TmaskStat, "Q_I_r", j ] ), pl = lowP, pu = highP, nfix = bpfK )
prod_bpf    <- bkfilter( log0( mcData[[ k ]][ TmaskStat, "Prod", j ] ), pl = lowP, pu = highP, nfix = bpfK )
u_bpf       <- bkfilter( log0( mcData[[ k ]][ TmaskStat, "U", j ] ), pl = lowP, pu = highP, nfix = bpfK )
p_bpf       <- bkfilter( log0( mcData[[ k ]][ TmaskStat, "P", j ] ), pl = lowP, pu = highP, nfix = bpfK )
# Augmented Dickey-Fuller tests for unit roots
adf_gdp_r[[ j ]]    <- adf.test( log0( mcData[[ k ]][ TmaskStat, "Real_Q_GDP", j ] ) )
adf_gdp_n[[ j ]]    <- adf.test( log0( mcData[[ k ]][ TmaskStat, "Q_GDP", j ] ) )
adf_gdp_gr[[ j ]]   <- adf.test( log0( mcData[[ k ]][ TmaskStat, "G_r", j ] ) )
adf_gdp_gn[[ j ]]   <- adf.test( log0( mcData[[ k ]][ TmaskStat, "G_n", j ] ) )
adf_cr[[ j ]]       <- adf.test( log0( mcData[[ k ]][ TmaskStat, "Q_C_r", j ] ) )
adf_ir[[ j ]]       <- adf.test( log0( mcData[[ k ]][ TmaskStat, "Q_I_r", j ] ) )
adf_p[[ j ]]        <- adf.test( log0( mcData[[ k ]][ TmaskStat, "P", j ] ) )
adf_prod[[ j ]]     <- adf.test( log0( mcData[[ k ]][ TmaskStat, "Prod", j ] ) )
# Standard deviations of filtered series
gdp_sd[ j ]   <- sd( gdp_bpf$cycle[ TmaskBpf, 1 ] )
cr_sd[ j ]    <- sd( cr_bpf$cycle[ TmaskBpf, 1 ] )
ir_sd[ j ]    <- sd( ir_bpf$cycle[ TmaskBpf, 1 ] )
prod_sd[ j ]  <- sd( prod_bpf$cycle[ TmaskBpf, 1 ] )
# Build the correlation structures
gdp_gdp[[ j ]]  <- ccf( gdp_bpf$cycle[ TmaskBpf, 1 ],
gdp_bpf$cycle[ TmaskBpf, 1 ],
lag.max = lags, plot = FALSE, na.action = na.pass )
cr_gdp[[ j ]] <- ccf( gdp_bpf$cycle[ TmaskBpf, 1 ],
cr_bpf$cycle[ TmaskBpf, 1 ],
lag.max = lags, plot = FALSE, na.action = na.pass )
ir_gdp[[ j ]] <- ccf( gdp_bpf$cycle[ TmaskBpf, 1 ],
ir_bpf$cycle[ TmaskBpf, 1 ],
lag.max = lags, plot = FALSE, na.action = na.pass )
p_gdp[[ j ]] <- ccf( gdp_bpf$cycle[ TmaskBpf, 1 ],
p_bpf$cycle[ TmaskBpf, 1 ],
lag.max = lags, plot = FALSE, na.action = na.pass )
prod_gdp[[ j ]] <- ccf( gdp_bpf$cycle[ TmaskBpf, 1 ],
prod_bpf$cycle[ TmaskBpf, 1 ],
lag.max = lags, plot = FALSE, na.action = na.pass )
u_gdp[[ j ]] <- ccf( gdp_bpf$cycle[ TmaskBpf, 1 ],
u_bpf$cycle[ TmaskBpf, 1 ],
lag.max = lags, plot = FALSE, na.action = na.pass )
}
# Applies t test to the mean lag results to test their significance (H0: lag < critCorr)
for(i in 1 : (2 * lags + 1) ){ #do for all lags
if(i != lags + 1)  # don't try to compute autocorrelation at lag 0
gdp_gdp_pval[ i ] <- t.test0( abs( unname( sapply( gdp_gdp, `[[`, "acf" ) )[ i, ] ), critCorr, CI )
cr_gdp_pval[ i ]  <- t.test0( abs( unname( sapply( cr_gdp, `[[`, "acf" ) )[ i, ] ), critCorr, CI )
ir_gdp_pval[ i ]  <- t.test0( abs( unname( sapply( ir_gdp, `[[`, "acf" ) )[ i, ] ), critCorr, CI )
p_gdp_pval[ i ]   <- t.test0( abs( unname( sapply( p_gdp, `[[`, "acf" ) )[ i, ] ), critCorr, CI )
prod_gdp_pval[ i ]<- t.test0( abs( unname( sapply( prod_gdp, `[[`, "acf" ) )[ i, ] ), critCorr, CI )
u_gdp_pval[ i ]   <- t.test0( abs( unname( sapply( u_gdp, `[[`, "acf" ) )[ i, ] ), critCorr, CI )
}
############### COMEÃAR AQUI #######################
#
# ---- Summary statistics table (averages, standard errors and p-values) ----
#
key.stats <- matrix(c(mean( gdp.growth ), mean( cReal.growth ), mean( iR.growth ),
mean( Am.growth ), mean( rw.growth ), mean( sT.growth ),
mean( tenure.growth ),
sd( gdp.growth ) / sqrt( nSize ), sd( cReal.growth ) / sqrt( nSize ),
sd( iR.growth ) / sqrt( nSize ), sd( Am.growth ) / sqrt( nSize ),
sd( rw.growth )/ sqrt( nSize ), sd( sT.growth )/ sqrt( nSize ),
sd( tenure.growth )/ sqrt( nSize ),
mean( unname( sapply( gdp.adf, `[[`, "statistic" ) ) ),
mean( unname( sapply( cReal.adf, `[[`, "statistic" ) ) ),
mean( unname( sapply( iR.adf, `[[`, "statistic" ) ) ),
mean( unname( sapply( Am.adf, `[[`, "statistic" ) ) ),
mean( unname( sapply( rw.adf, `[[`, "statistic" ) ) ),
mean( unname( sapply( sT.adf, `[[`, "statistic" ) ) ),
mean( unname( sapply( tenure.adf, `[[`, "statistic" ) ) ),
sd( unname( sapply( gdp.adf, `[[`, "statistic" ) ) ) / sqrt( nSize ),
sd( unname( sapply( cReal.adf, `[[`, "statistic" ) ) ) / sqrt( nSize ),
sd( unname( sapply( iR.adf, `[[`, "statistic" ) ) ) / sqrt( nSize ),
sd( unname( sapply( Am.adf, `[[`, "statistic" ) ) ) / sqrt( nSize ),
sd( unname( sapply( rw.adf, `[[`, "statistic" ) ) ) / sqrt( nSize ),
sd( unname( sapply( sT.adf, `[[`, "statistic" ) ) ) / sqrt( nSize ),
sd( unname( sapply( tenure.adf, `[[`, "statistic" ) ) ) / sqrt( nSize ),
mean( unname( sapply( gdp.adf, `[[`, "p.value" ) ) ),
mean( unname( sapply( cReal.adf, `[[`, "p.value" ) ) ),
mean( unname( sapply( iR.adf, `[[`, "p.value" ) ) ),
mean( unname( sapply( Am.adf, `[[`, "p.value" ) ) ),
mean( unname( sapply( rw.adf, `[[`, "p.value" ) ) ),
mean( unname( sapply( sT.adf, `[[`, "p.value" ) ) ),
mean( unname( sapply( tenure.adf, `[[`, "p.value" ) ) ),
sd( unname( sapply( gdp.adf, `[[`, "p.value" ) ) ) / sqrt( nSize ),
sd( unname( sapply( cReal.adf, `[[`, "p.value" ) ) ) / sqrt( nSize ),
sd( unname( sapply( iR.adf, `[[`, "p.value" ) ) ) / sqrt( nSize ),
sd( unname( sapply( Am.adf, `[[`, "p.value" ) ) ) / sqrt( nSize ),
sd( unname( sapply( rw.adf, `[[`, "p.value" ) ) ) / sqrt( nSize ),
sd( unname( sapply( sT.adf, `[[`, "p.value" ) ) ) / sqrt( nSize ),
sd( unname( sapply( tenure.adf, `[[`, "p.value" ) ) ) / sqrt( nSize ),
mean( unname( sapply( gdp.bpf.adf, `[[`, "statistic" ) ) ),
mean( unname( sapply( cReal.bpf.adf, `[[`, "statistic" ) ) ),
mean( unname( sapply( iR.bpf.adf, `[[`, "statistic" ) ) ),
mean( unname( sapply( Am.bpf.adf, `[[`, "statistic" ) ) ),
mean( unname( sapply( rw.bpf.adf, `[[`, "statistic" ) ) ),
mean( unname( sapply( sT.bpf.adf, `[[`, "statistic" ) ) ),
mean( unname( sapply( tenure.bpf.adf, `[[`, "statistic" ) ) ),
sd( unname( sapply( gdp.bpf.adf, `[[`, "statistic" ) ) ) / sqrt( nSize ),
sd( unname( sapply( cReal.bpf.adf, `[[`, "statistic" ) ) ) / sqrt( nSize ),
sd( unname( sapply( iR.bpf.adf, `[[`, "statistic" ) ) ) / sqrt( nSize ),
sd( unname( sapply( Am.bpf.adf, `[[`, "statistic" ) ) ) / sqrt( nSize ),
sd( unname( sapply( rw.bpf.adf, `[[`, "statistic" ) ) ) / sqrt( nSize ),
sd( unname( sapply( sT.bpf.adf, `[[`, "statistic" ) ) ) / sqrt( nSize ),
sd( unname( sapply( tenure.bpf.adf, `[[`, "statistic" ) ) ) / sqrt( nSize ),
mean( unname( sapply( gdp.bpf.adf, `[[`, "p.value" ) ) ),
mean( unname( sapply( cReal.bpf.adf, `[[`, "p.value" ) ) ),
mean( unname( sapply( iR.bpf.adf, `[[`, "p.value" ) ) ),
mean( unname( sapply( Am.bpf.adf, `[[`, "p.value" ) ) ),
mean( unname( sapply( rw.bpf.adf, `[[`, "p.value" ) ) ),
mean( unname( sapply( sT.bpf.adf, `[[`, "p.value" ) ) ),
mean( unname( sapply( tenure.bpf.adf, `[[`, "p.value" ) ) ),
sd( unname( sapply( gdp.bpf.adf, `[[`, "p.value" ) ) ) / sqrt( nSize ),
sd( unname( sapply( cReal.bpf.adf, `[[`, "p.value" ) ) ) / sqrt( nSize ),
sd( unname( sapply( iR.bpf.adf, `[[`, "p.value" ) ) ) / sqrt( nSize ),
sd( unname( sapply( Am.bpf.adf, `[[`, "p.value" ) ) ) / sqrt( nSize ),
sd( unname( sapply( rw.bpf.adf, `[[`, "p.value" ) ) ) / sqrt( nSize ),
sd( unname( sapply( sT.bpf.adf, `[[`, "p.value" ) ) ) / sqrt( nSize ),
sd( unname( sapply( tenure.bpf.adf, `[[`, "p.value" ) ) ) / sqrt( nSize ),
mean(gdp.sd ), mean(cReal.sd ), mean(iR.sd ), mean(Am.sd ),
mean(rw.sd ), mean(sT.sd ), mean(tenure.sd ),
sd( gdp.sd ) / sqrt( nSize ), sd( cReal.sd ) / sqrt( nSize ),
sd( iR.sd ) / sqrt( nSize ), sd( Am.sd ) / sqrt( nSize ),
sd( rw.sd ) / sqrt( nSize ), sd( sT.sd ) / sqrt( nSize ),
sd( tenure.sd ) / sqrt( nSize ),
1, mean( cReal.sd ) / mean( gdp.sd ), mean( iR.sd ) / mean( gdp.sd ),
mean( Am.sd ) / mean( gdp.sd ), mean( rw.sd ) / mean( gdp.sd ),
mean( sT.sd ) / mean( gdp.sd ), mean( tenure.sd ) / mean(gdp.sd ) ),
ncol = 7, byrow = T)
colnames( key.stats ) <- c( "GDP (output)", "Consumption", "Investment", "Product.",
"Real wage", "Ten. skills", "Tenure" )
rownames( key.stats ) <- c( "avg. growth rate", " (s.e.)",
"ADF test (logs)", " (s.e.)", " (p-val.)", " (s.e.)",
"ADF test (bpf)", " (s.e.)", " (p-val.)", " (s.e.)",
" s.d. (bpf)", " (s.e.)",
" relative s.d. (GDP)" )
textplot( formatC( key.stats, digits = sDigits, format = "g" ), cmar = 2 )
title <- paste( "Key statistics and unit roots tests for cycles (", legends[ k ], ")" )
subTitle <- paste( eval( bquote(paste0( "( bpf: Baxter-King bandpass-filtered series, low = ", .( lowP ),
"Q / high = ", .( highP ), "Q / order = ", .( bpfK ),
" / MC runs = ", .( nSize ), " / period = ",
.( warmUpStat + 1 ), " - ", .( nTstat ), " )" ) ) ),
eval( bquote( paste0( "( ADF test H0: there are unit roots / non-stationary at ",
.( (1 - CI ) * 100), "% level", " )" ) ) ), sep ="\n" )
title( main = title, sub = subTitle )
#
# ---- Correlation structure tables (lags, sta
corr.struct.1 <- matrix(c(colMeans(t( unname( sapply(gdp.gdp, `[[`, "acf" ) ) ), na.rm = T),
colSds(t( unname( sapply(gdp.gdp, `[[`, "acf" ) ) ), na.rm = T) / sqrt( nSize ),
gdp.gdp.pval,
colMeans(t( unname( sapply(cReal.gdp, `[[`, "acf" ) ) ), na.rm = T),
colSds(t( unname( sapply(cReal.gdp, `[[`, "acf" ) ) ), na.rm = T) / sqrt( nSize ),
cReal.gdp.pval,
colMeans(t( unname( sapply(iR.gdp, `[[`, "acf" ) ) ), na.rm = T),
colSds(t( unname( sapply(iR.gdp, `[[`, "acf" ) ) ), na.rm = T) / sqrt( nSize ),
iR.gdp.pval,
colMeans(t( unname( sapply(EItot.gdp, `[[`, "acf" ) ) ), na.rm = T),
colSds(t( unname( sapply(EItot.gdp, `[[`, "acf" ) ) ), na.rm = T) / sqrt( nSize ),
EItot.gdp.pval,
colMeans(t( unname( sapply(dNtot.gdp, `[[`, "acf" ) ) ), na.rm = T),
colSds(t( unname( sapply(dNtot.gdp, `[[`, "acf" ) ) ), na.rm = T) / sqrt( nSize ),
dNtot.gdp.pval,
colMeans(t( unname( sapply(U.gdp, `[[`, "acf" ) ) ), na.rm = T),
colSds(t( unname( sapply(U.gdp, `[[`, "acf" ) ) ), na.rm = T) / sqrt( nSize ),
U.gdp.pval,
colMeans(t( unname( sapply(Am.gdp, `[[`, "acf" ) ) ), na.rm = T),
colSds(t( unname( sapply(Am.gdp, `[[`, "acf" ) ) ), na.rm = T) / sqrt( nSize ),
Am.gdp.pval,
colMeans(t( unname( sapply(Mutot.gdp, `[[`, "acf" ) ) ), na.rm = T),
colSds(t( unname( sapply(Mutot.gdp, `[[`, "acf" ) ) ), na.rm = T) / sqrt( nSize ),
Mutot.gdp.pval,
colMeans(t( unname( sapply(totDeb.gdp, `[[`, "acf" ) ) ), na.rm = T),
colSds(t( unname( sapply(totDeb.gdp, `[[`, "acf" ) ) ), na.rm = T) / sqrt( nSize ),
totDeb.gdp.pval,
colMeans(t( unname( sapply(liqSale.gdp, `[[`, "acf" ) ) ), na.rm = T),
colSds(t( unname( sapply(liqSale.gdp, `[[`, "acf" ) ) ), na.rm = T) / sqrt( nSize ),
liqSale.gdp.pval,
colMeans(t( unname( sapply(bankrup.gdp, `[[`, "acf" ) ) ), na.rm = T),
colSds(t( unname( sapply(bankrup.gdp, `[[`, "acf" ) ) ), na.rm = T) / sqrt( nSize ),
bankrup.gdp.pval ),
ncol = 2 * lags + 1, byrow = T)
colnames( corr.struct.1 ) <- gdp.gdp[[1]]$lag
rownames( corr.struct.1 ) <- c( "GDP (output)", " (s.e.)", " (p-val.)",
"Consumption", " (s.e.)", " (p-val.)",
"Investment", " (s.e.)", " (p-val.)",
"Net investment", " (s.e.)", " (p-val.)",
"Change in inventories", " (s.e.)", " (p-val.)",
"Unemployment rate", " (s.e.)", " (p-val.)",
"Productivity", " (s.e.)", " (p-val.)",
"Mark-up (sector 2)", " (s.e.)", " (p-val.)",
"Total firm debt", " (s.e.)", " (p-val.)",
"Liquidity-to-sales ratio", " (s.e.)", " (p-val.)",
"Bankruptcy rate", " (s.e.)", " (p-val.)" )
corr.struct.2 <- matrix(c(colMeans(t( unname( sapply(gdp.gdp, `[[`, "acf" ) ) ), na.rm = T),
colSds(t( unname( sapply(gdp.gdp, `[[`, "acf" ) ) ), na.rm = T) / sqrt( nSize ),
gdp.gdp.pval,
colMeans(t( unname( sapply(cReal.gdp, `[[`, "acf" ) ) ), na.rm = T),
colSds(t( unname( sapply(cReal.gdp, `[[`, "acf" ) ) ), na.rm = T) / sqrt( nSize ),
cReal.gdp.pval,
colMeans(t( unname( sapply(iR.gdp, `[[`, "acf" ) ) ), na.rm = T),
colSds(t( unname( sapply(iR.gdp, `[[`, "acf" ) ) ), na.rm = T) / sqrt( nSize ),
iR.gdp.pval,
colMeans(t( unname( sapply(Am.gdp, `[[`, "acf" ) ) ), na.rm = T),
colSds(t( unname( sapply(Am.gdp, `[[`, "acf" ) ) ), na.rm = T) / sqrt( nSize ),
Am.gdp.pval,
colMeans( t( unname( sapply( netEntr.gdp, `[[`, "acf" ) ) ), na.rm = T ),
colSds( t( unname( sapply( netEntr.gdp, `[[`, "acf" ) ) ), na.rm = T ) /
sqrt( nSize ),
netEntr.gdp.pval,
colMeans( t( unname( sapply( entry.gdp, `[[`, "acf" ) ) ), na.rm = T ),
colSds( t( unname( sapply( entry.gdp, `[[`, "acf" ) ) ), na.rm = T ) /
sqrt( nSize ),
entry.gdp.pval,
colMeans(t( unname( sapply(rw.gdp, `[[`, "acf" ) ) ), na.rm = T),
colSds(t( unname( sapply(rw.gdp, `[[`, "acf" ) ) ), na.rm = T) / sqrt( nSize ),
rw.gdp.pval,
colMeans(t( unname( sapply(U.gdp, `[[`, "acf" ) ) ), na.rm = T),
colSds(t( unname( sapply(U.gdp, `[[`, "acf" ) ) ), na.rm = T) / sqrt( nSize ),
U.gdp.pval,
colMeans(t( unname( sapply(V.gdp, `[[`, "acf" ) ) ), na.rm = T),
colSds(t( unname( sapply(V.gdp, `[[`, "acf" ) ) ), na.rm = T) / sqrt( nSize ),
V.gdp.pval,
colMeans(t( unname( sapply(Lentry.gdp, `[[`, "acf" ) ) ), na.rm = T),
colSds(t( unname( sapply(Lentry.gdp, `[[`, "acf" ) ) ), na.rm = T) / sqrt( nSize ),
Lentry.gdp.pval,
colMeans(t( unname( sapply(Lexit.gdp, `[[`, "acf" ) ) ), na.rm = T),
colSds(t( unname( sapply(Lexit.gdp, `[[`, "acf" ) ) ), na.rm = T) / sqrt( nSize ),
Lexit.gdp.pval),
ncol = 2 * lags + 1, byrow = T)
colnames( corr.struct.2 ) <- gdp.gdp[[1]]$lag
rownames( corr.struct.2 ) <- c( "GDP (output)", " (s.e.)", " (p-val.)",
"Consumption", " (s.e.)", " (p-val.)",
"Investment", " (s.e.)", " (p-val.)",
"Productivity", " (s.e.)", " (p-val.)",
"Net entry", " (s.e.)", " (p-val.)",
"Entry", " (s.e.)", " (p-val.)",
"Wage", " (s.e.)", " (p-val.)",
"Unemployment rate", " (s.e.)", " (p-val.)",
"Vacancy rate", " (s.e.)", " (p-val.)",
"Hiring rate", " (s.e.)", " (p-val.)",
"Firing rate", " (s.e.)", " (p-val.)" )
title <- paste( "Correlation structure for GDP (", legends[ k ], ")" )
subTitle <- paste( eval( bquote( paste0( "( non-rate/ratio series are Baxter-King bandpass-filtered, low = ",
.( lowP ), "Q / high = ", .( highP ), "Q / order = ", .( bpfK ),
" / MC runs = ", .( nSize ), " / period = ",
.( warmUpStat + 1 ), " - ", .( nTstat ), " )" ) ) ),
eval( bquote ( paste0( "( test H0: lag coefficient is not significant at ",
.( ( 1 - CI ) * 100), "% level", " )" ) ) ), sep ="\n" )
textplot( formatC( corr.struct.1, digits = sDigits, format = "g" ), cmar = 1 )
title( main = title, sub = subTitle )
textplot( formatC( corr.struct.2, digits = sDigits, format = "g" ), cmar = 1 )
title( main = title, sub = subTitle )
# Write tables to the disk as CSV files for Excel
write.csv( key.stats, quote = FALSE,
paste0( folder, "/", outDir, "/", repName, k, "_key_stats.csv" ) )
write.csv( rbind( corr.struct.1, corr.struct.2 ), quote = FALSE,
paste0( folder, "/", outDir, "/", repName, k, "_corr_struct.csv" ) )
}
#
# ---- Aggregated variables stationarity and ergodicity tests ----
#
# select data to plot
for( k in 1 : nExp ){
statErgo <- ergod.test.lsd( mcData[[ k ]][ TmaskStat, , ], signif = 1 - CI,
vars = statErgo.vars )
# plot table
textplot( statErgo, cmar = 2, rmar = 0.5 )
title( main = paste( "Stationarity, i.i.d. and ergodicity tests (", legends[ k ], ")" ),
sub = paste( "( average p-values for testing H0 and rate of rejection of H0 / MC runs =", nSize, "/ period =", warmUpStat + 1, "-", nTstat, ")\n ( ADF/PP H0: non-stationary, KPSS H0: stationary, BDS H0: i.i.d., KS/AD/WW H0: ergodic )\n( significance =",
1 - CI, ")" ) )
# write to disk
write.csv( statErgo, quote = FALSE,
paste0( folder, "/", outDir, "/", repName, k, "_ergod_tests.csv" ) )
}
#
# ---- GDP long-term recovery times table ----
#
rec.stats <- array( dim = c( 5, nSize, nExp ) )
rec.stats.mc <- array( dim = c( 2 * dim( rec.stats )[ 1 ], nExp ) )
rec.cases <- array( data = 0, dim = c( 2 , nExp ) )
rec.starts <- rec.times <- array( list( ), dim = c( nSize, nExp ) )
for( k in 1 : nExp ) {      # for each experiment
for( j in 1 : nSize ) {   # for each MC case
# calculate long-term ex post growth rate trend
growthTrend <- hpfilter( mcData[[ k ]][ , "diff_GDP", j ], smoothing )$trend[ , 1 ]
# Calculate recovery statistics for GDP to the pre-crisis trend
recovery <- FALSE
recStart <- recTime <- recDepth <- recCost <- vector( mode = "numeric" )
preCrisisGDP <- gTrend <- timeCrisis <- depthCrisis <- costCrisis <- NA
for( i in TmaskStat ) {
if( recovery ) {                                              # in a recovery?
preCrisisGDP <- preCrisisGDP + gTrend                       # update pre crisis trend
if( log( mcData[[ k ]][ i, "GDP", j ] ) >= preCrisisGDP ) { # recovery is over?
recovery <- FALSE
if( i - timeCrisis > crisisLen ) { # record only crisis lasting longer than x periods
recStart <- append( recStart, timeCrisis )
recTime <- append( recTime, i - timeCrisis )
recDepth <- append( recDepth, depthCrisis )
recCost <- append( recCost, costCrisis )
}
} else {                                                    # recovery not over
gap <- preCrisisGDP - log( mcData[[ k ]][ i, "GDP", j ] ) # update recovery statistics
depthCrisis <- max( depthCrisis, gap )
costCrisis <- costCrisis + gap
}
}
if( ! recovery && mcData[[ k ]][ i, "diff_GDP", j ] < crisisTh && i > crisisPre ) {
recovery <- TRUE
timeCrisis <- i
depthCrisis <- costCrisis <- 0
preCrisisGDP <- log( mean( mcData[[ k ]][ ( i - crisisPre ) : ( i - 1 ), "GDP", j ] ) )
gTrend <- mean( growthTrend[ ( i - crisisPre ) : ( i - 1 ) ], na.rm = TRUE )
depthCrisis <- costCrisis <- preCrisisGDP - log( mcData[[ k ]][ i, "GDP", j ] )
}
}
# prepare to consolidate MC results
if( length( recTime ) > 0 ) {
rec.stats[ , j, k ] <- c( length( recTime ), mean( recTime ), sd( recTime ),
mean( recDepth ), mean( recCost ) )
rec.times[[ j, k ]] <- recTime
rec.starts[[ j, k ]] <- recStart
# record case with more average costs crises
rankCr <- mean( recCost )
if( rankCr > rec.cases[ 2, k ] ) {
rec.cases[ 1, k ] <- j
rec.cases[ 2, k ] <- rankCr
}
} else {
rec.stats[ , j, k ] <- c( rep( NA, dim( rec.stats )[ 1 ] ) )
rec.times[[ j, k ]] <- NA
rec.starts[[ j, k ]] <- NA
}
}
# Calculate average recovery statistics for the experiment
for( i in 1 : ( dim( rec.stats )[ 1 ] ) ) {
rec.stats.mc[ 2 * i - 1, k ] <- mean( rec.stats[ i, , k ], na.rm = TRUE )
rec.stats.mc[ 2 * i, k ] <- sd( rec.stats[ i, , k ], na.rm = TRUE ) / sqrt( nSize )
}
}
recovery <- matrix( c( rec.stats.mc[ 1, 1 ], rec.stats.mc[ 2, 1 ],
rec.stats.mc[ 3, 1 ], rec.stats.mc[ 4, 1 ],
rec.stats.mc[ 5, 1 ], rec.stats.mc[ 6, 1 ],
rec.stats.mc[ 7, 1 ], rec.stats.mc[ 8, 1 ],
rec.stats.mc[ 9, 1 ], rec.stats.mc[ 10, 1 ] ) )
recovery.labels <- legends[ 1 ]
if( nExp > 1 ){
# Create 2D table
for( k in 2 : nExp ) {
recovery <- cbind( recovery, c( rec.stats.mc[ 1, k ], rec.stats.mc[ 2, k ],
rec.stats.mc[ 3, k ], rec.stats.mc[ 4, k ],
rec.stats.mc[ 5, k ], rec.stats.mc[ 6, k ],
rec.stats.mc[ 7, k ], rec.stats.mc[ 8, k ],
rec.stats.mc[ 9, k ], rec.stats.mc[ 10, k ] ) )
recovery.labels <- append( recovery.labels, legends[ k ] )
}
}
colnames( recovery ) <- recovery.labels
rownames( recovery ) <- c( "Avg. number of crisis", "(s.e.)", "Avg. recovery periods",
"(s.e.)", "Std. dev. rec. periods", "(s.e.)",
"Avg. crisis peak", "(s.e.)", "Avg. crisis loss", "(s.e.)" )
textplot( formatC( recovery, digits = sDigits, format = "g" ), cmar = 1 )
title <- paste( "GDP long-term trend recovery after crisis ( all experiments )" )
subTitle <- paste( "( MC standard error in parentheses / MC runs =",
nSize, "/ period =", warmUpStat + 1, "-", nTstat, ")\n",
"( crisis definition: GDP contraction larger than", abs( crisisTh ) * 100,
"%, for more than", crisisLen, "periods )\n",
"( pre-crisis trend estimated using an HP filter with smoothing parameter =",
smoothing, "averaged for", crisisPre, "periods )" )
title( main = title, sub = subTitle )
# Write table to the disk as CSV files for Excel
write.csv( recovery, quote = FALSE,
paste0( folder, "/", outDir, "/", repName, k, "_GDP_recovery.csv" ) )
#
# ---- GDP recovery sample run plot ----
#
for( k in 1 : nExp ) {                                # for each experiment
if( crisisRun == 0 )
j <- rec.cases[ 1, k ]                            # auto-selected MC run
else
j <- crisisRun                                    # or use the user's selected
if( j == 0 )                                        # no crisis?
j <- 1                                            # pick first
plot_recovery( mcData[[ k ]][ , "GDP", j ], mcData[[ k ]][ , "diff_GDP", j ],
mask = TmaskStat, warm = warmUpPlot, mrk = transMk,
strt = rec.starts[[ j, k ]], dur = rec.times[[ j, k ]],
per = crisisPre, xlab = "Time", ylab = "Log GDP",
tit = paste( "GDP long-term trend recovery after crisis sample (", legends[ k ], ")" ),
subtit = paste( "( dashed line: pre-crisis trend / gray boxes: trend recovey period / MC case =",
j, "/ period =", warmUpStat + 1, "-", nTstat, ")" ) )
}
#
# ======= COMPARISON OF EXPERIMENTS =======
#
cat( "\nRunning experiments comparison...\n" )
box_plots( mcData, nExp, nSize, TmaxStat, TmaskStat, warmUpStat,
nTstat, legends, legendList, sDigits, bPlotCoef,
bPlotNotc, folder, outDir, repName )
#
# ======= CRISIS RECOVERY REPORT =======
#
if( crisesPlt ) {
cat( "\nGenerating crises report...\n")
# Close main plot file
dev.off()
# Select type of output
if( raster ){
# Open PNG (bitmap) files for output
png( paste0( folder, "/", outDir, "/", repName, "_crisis_%d.png" ),
width = plotW, height = plotH, units = "in", res = res )
} else {
# Open PDF plot file for output
pdf(paste0( folder, "/", outDir, "/", repName, "_crisis.pdf" ),
width = plotW, height = plotH )
par( mfrow = c ( plotRows, plotCols ) )             # define plots per page
}
# Plot all GDP recovery runs
for( k in 1 : nExp )                                  # for each experiment
for( j in 1 : nSize )                               # for each MC case
plot_recovery( mcData[[ k ]][ , "GDP", j ], mcData[[ k ]][ , "diff_GDP", j ],
mask = TmaskStat, warm = warmUpPlot, mrk = transMk,
strt = rec.starts[[ j, k ]], dur = rec.times[[ j, k ]],
per = crisisPre, xlab = "Time", ylab = "Log GDP",
tit = paste( "GDP long-term trend recovery after crisis sample (", legends[ k ], ")" ),
subtit = paste( "( dashed line: pre-crisis trend / gray boxes: trend recovey period / MC case =",
j, "/ period =", warmUpStat + 1, "-", nTstat, ")" ) )
}
cat( "\nDone...\n" )
#******************************************************************
#
# ------------- Exception handling code (tryCatch) -------------
#
#******************************************************************
}, interrupt = function( ex ) {
cat( "An interrupt was detected.\n" )
print( ex )
textplot( "Report incomplete due to interrupt." )
}, error = function(ex) {
cat( "An error was detected.\n" )
print( ex )
textplot( "Report incomplete due to processing error." )
}, finally = {
options( warn = 0 )
cat( "\n", as.character( Sys.time( ) ), "-> Releasing resources...\n\n" )
totalTime <- proc.time( ) - startTime
print( totalTime )
# Close PDF plot file
dev.off( )
} )
library(tidyverse)
install.packages("tidyverse")
library(tidyverse)
install.packages("eurostat")
library(eurostat)
search <- search_eurostat("population", type = "table")
View(search)
search <- search_eurostat("all", type = "table")
View(search)
View(search)
source('D:/R/mmm_global_analysis.R')
setwd("D:/R")
source('D:/R/mmm_global_analysis.R')
source('D:/R/mmm_global_analysis.R')
source('D:/R/mmm_global_analysis.R')
source('D:/R/mmm_global_analysis.R')
source('D:/R/mmm_global_analysis.R')
source('D:/R/mmm_global_analysis.R')
source('D:/R/mmm_global_analysis.R')
source('D:/R/mmm_global_analysis.R')
source('D:/R/mmm_global_analysis.R')
source('D:/R/mmm_global_analysis.R')
source('D:/R/mmm_global_analysis.R')
source('D:/R/mmm_global_analysis.R')
source('D:/R/mmm_global_analysis.R')
source('D:/R/mmm_global_analysis.R')
source('D:/R/mmm_global_analysis.R')
source('D:/R/mmm_global_analysis.R')
setwd("C:/Lsd/Work/MMM_CORE/R")
source('C:/Lsd/Work/MMM_CORE/R/mmm_macro_analysis.R')
source('C:/Lsd/Work/MMM_CORE/R/mmm_macro_analysis.R')
source('C:/Lsd/Work/MMM_CORE/R/mmm_macro_analysis.R')
source('C:/Lsd/Work/MMM_CORE/R/mmm_macro_analysis.R')
